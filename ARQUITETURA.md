# ğŸ—ï¸ Arquitetura do Sistema

## VisÃ£o Geral

O sistema utiliza **LangGraph** para orquestrar um fluxo de trabalho complexo de forma declarativa e escalÃ¡vel.

## Diagrama do Grafo de ExecuÃ§Ã£o

```mermaid
graph TD
    Start([InÃ­cio]) --> FetchRefunds[Buscar Pedidos com Reembolso]
    
    FetchRefunds --> GetDetails[Obter Detalhes do Pedido]
    
    GetDetails --> Decision1{Tem dados<br/>para processar?}
    
    Decision1 -->|NÃ£o tem apply_id| NextOrder[PrÃ³ximo Pedido]
    Decision1 -->|Tem dados completos| Generate[Gerar Defesa com IA]
    Decision1 -->|Fim da lista| End([Fim])
    
    NextOrder --> GetDetails
    
    Generate --> Submit[Enviar ContestaÃ§Ã£o]
    
    Submit --> Decision2{Mais pedidos<br/>na fila?}
    
    Decision2 -->|Sim| GetDetails
    Decision2 -->|NÃ£o| End
    
    style Generate fill:#4CAF50,color:#fff
    style Submit fill:#2196F3,color:#fff
    style Decision1 fill:#FF9800,color:#fff
    style Decision2 fill:#FF9800,color:#fff
```

## Componentes Principais

### 1. **Config (`config.py`)**

Gerencia variÃ¡veis de ambiente usando Pydantic Settings.

```python
class Settings(BaseSettings):
    llm_provider: str  # openai | gemini
    llm_model: str     # gpt-4o | gemini-1.5-pro
    openai_api_key: str
    google_api_key: str
    base_api_url: str
```

### 2. **Models (`models.py`)**

Define schemas Pydantic para tipar as respostas da API:

- `RefundListResponse`: Lista de pedidos com reembolso
- `OrderDetailResponse`: Detalhes completos do pedido
- `RefundDetail`: InformaÃ§Ãµes especÃ­ficas do reembolso (motivo, imagem, etc.)
- `AppealRequest`: Payload para enviar contestaÃ§Ã£o

### 3. **API Client (`api_client.py`)**

Cliente HTTP usando `httpx` para comunicaÃ§Ã£o com a API 99Food.

```python
class APIClient:
    def get_refund_orders(...) -> Dict
    def get_order_detail(order_id) -> Dict
    def submit_appeal(order_id, apply_id, comments) -> Dict
```

### 4. **LLM Client (`llm_client.py`)**

Factory Pattern para abstrair provedores de IA.

```python
# Interface abstrata
class LLMClient(ABC):
    def generate_defense(reason, items, image_url) -> str

# ImplementaÃ§Ãµes concretas
class OpenAILLMClient(LLMClient)  # GPT-4o com visÃ£o
class GeminiLLMClient(LLMClient)   # Gemini 1.5 Pro com visÃ£o

# Factory
def create_llm_client(settings) -> LLMClient
```

**Capacidade Multimodal:**

Ambos os clientes suportam anÃ¡lise de imagens. Quando `image_url` Ã© fornecido, a IA analisa:
- O texto da reclamaÃ§Ã£o
- A imagem de prova
- Os itens do pedido

E gera uma defesa que considera todos esses elementos.

### 5. **Agent Graph (`agent_graph.py`)**

CoraÃ§Ã£o do sistema. Define o grafo de execuÃ§Ã£o usando LangGraph.

#### Estado do Agente

```python
class AgentState(TypedDict):
    start_date: str
    end_date: str
    order_ids: List[str]
    current_order_index: int
    current_order_id: Optional[str]
    current_apply_id: Optional[str]
    current_reason: Optional[str]
    current_items: Optional[str]
    current_image_url: Optional[str]
    generated_defense: Optional[str]
    appeals_sent: int
    errors: List[str]
```

#### NÃ³s do Grafo

1. **fetch_refund_orders**: Busca lista de pedidos
2. **get_order_details**: Extrai detalhes de um pedido
3. **generate_defense**: Invoca IA para criar argumentaÃ§Ã£o
4. **submit_appeal**: Envia contestaÃ§Ã£o via API

#### Arestas Condicionais

- `should_generate_defense`: Decide se hÃ¡ dados suficientes para processar
- `should_continue`: Decide se hÃ¡ mais pedidos na fila

### 6. **Main (`main.py`)**

Script principal que orquestra tudo:

1. Carrega configuraÃ§Ãµes
2. Instancia clientes (API + LLM)
3. Cria e executa o agente
4. Exibe resumo final

## Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ConfiguraÃ§Ãµes (.env)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      main.py                             â”‚
â”‚  - Carrega settings                                      â”‚
â”‚  - Cria APIClient                                        â”‚
â”‚  - Cria LLMClient (OpenAI/Gemini)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RefundContestationAgent                     â”‚
â”‚                                                          â”‚
â”‚  Estado Inicial:                                         â”‚
â”‚  {                                                       â”‚
â”‚    order_ids: [],                                        â”‚
â”‚    current_order_index: 0,                               â”‚
â”‚    appeals_sent: 0,                                      â”‚
â”‚    ...                                                   â”‚
â”‚  }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   API 99Food      â”‚   â”‚   LLM Provider    â”‚
    â”‚   (localhost)     â”‚   â”‚ (OpenAI/Gemini)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                       â”‚
                â”‚ GET /orders/refunds   â”‚
                â”‚ POST /orders/detail   â”‚
                â”‚ POST /orders/appeal   â”‚
                â”‚                       â”‚
                â”‚                       â”‚ analyze(text+image)
                â”‚                       â”‚ â†’ defense_text
                â”‚                       â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Estado Final  â”‚
                    â”‚               â”‚
                    â”‚ appeals_sent  â”‚
                    â”‚ errors[]      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PadrÃµes de Projeto Utilizados

### 1. **Factory Pattern**

Usado em `llm_client.py` para criar o provedor correto:

```python
def create_llm_client(settings: Settings) -> LLMClient:
    if settings.llm_provider == "openai":
        return OpenAILLMClient(...)
    elif settings.llm_provider == "gemini":
        return GeminiLLMClient(...)
```

### 2. **State Machine (via LangGraph)**

O grafo funciona como uma mÃ¡quina de estados, onde cada nÃ³ transforma o estado:

```python
state = workflow.invoke(initial_state)
# estado passa por cada nÃ³ e Ã© transformado
```

### 3. **Strategy Pattern**

A interface `LLMClient` permite trocar estratÃ©gias de IA sem mudar o cÃ³digo:

```python
# Ambos implementam a mesma interface
defense = llm_client.generate_defense(...)
# Funciona com OpenAI OU Gemini
```

### 4. **Builder Pattern**

O grafo Ã© construÃ­do de forma fluente:

```python
workflow = StateGraph(AgentState)
workflow.add_node("fetch", fetch_fn)
workflow.add_edge("fetch", "process")
workflow.add_conditional_edges(...)
return workflow.compile()
```

## Escalabilidade

### Como Adicionar Novo Provedor de IA

1. Crie uma classe em `llm_client.py`:

```python
class ClaudeLLMClient(LLMClient):
    def generate_defense(self, reason, items, image_url):
        # Implementar chamada para Claude
        pass
```

2. Adicione ao factory:

```python
def create_llm_client(settings):
    if settings.llm_provider == "claude":
        return ClaudeLLMClient(...)
```

3. Configure no `.env`:

```env
LLM_PROVIDER=claude
CLAUDE_API_KEY=...
```

### Como Adicionar Novo NÃ³ no Grafo

```python
def validate_order(self, state: AgentState) -> AgentState:
    # LÃ³gica de validaÃ§Ã£o
    return state

# No _build_graph:
workflow.add_node("validate", self.validate_order)
workflow.add_edge("get_order_details", "validate")
workflow.add_edge("validate", "generate_defense")
```

## Logs e Monitoramento

O sistema usa `logging` do Python com nÃ­veis:

- **INFO**: Progresso normal (ğŸ” âœ…)
- **WARNING**: SituaÃ§Ãµes anormais mas nÃ£o fatais (âš ï¸)
- **ERROR**: Falhas que impedem processamento (âŒ)

Exemplo de log:

```
2026-01-28 21:00:00 - INFO - ğŸ” Buscando pedidos com reembolso...
2026-01-28 21:00:01 - INFO - âœ… Encontrados 9 pedidos
2026-01-28 21:00:02 - INFO - ğŸ“„ Buscando detalhes do pedido 5764655...
2026-01-28 21:00:03 - INFO - ğŸ–¼ï¸  Imagem: SIM
2026-01-28 21:00:05 - INFO - ğŸ¤– Gerando defesa com IA...
2026-01-28 21:00:08 - INFO - ğŸ’¬ Defesa gerada: Consideramos...
2026-01-28 21:00:09 - INFO - âœ… ContestaÃ§Ã£o enviada com sucesso
```

## Tratamento de Erros

Cada nÃ³ trata seus prÃ³prios erros e registra no estado:

```python
try:
    # operaÃ§Ã£o
except Exception as e:
    logger.error(f"âŒ Erro: {e}")
    state["errors"].append(f"node_name: {str(e)}")
```

O grafo continua executando mesmo com erros parciais, permitindo processar o mÃ¡ximo de pedidos possÃ­vel.

## SeguranÃ§a

- âœ… API Keys nunca sÃ£o commitadas (`.gitignore`)
- âœ… `.env` nÃ£o Ã© versionado
- âœ… Timeout de 30s para requisiÃ§Ãµes HTTP
- âœ… ValidaÃ§Ã£o de schemas com Pydantic

## Performance

- **RequisiÃ§Ãµes**: httpx com timeout configurÃ¡vel
- **IA**: Limite de 300 tokens por resposta
- **Processamento**: Sequencial (um pedido por vez)

Para melhorar:
- Adicionar processamento paralelo com `asyncio`
- Cache de respostas da IA para motivos similares
- Batch de mÃºltiplas contestaÃ§Ãµes em uma requisiÃ§Ã£o
